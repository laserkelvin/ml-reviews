{
    "componentChunkName": "component---node-modules-gatsby-theme-kb-src-templates-topic-js",
    "path": "/notes/reinforcement learning",
    "result": {"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"reinforcement learning\"), mdx(\"p\", null, \"Teaching an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"agent\",\n    \"title\": \"agent\"\n  }, \"[[agent]]\"), \" to maximize a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reward\",\n    \"title\": \"reward\"\n  }, \"[[reward]]\"), \" from actioning on the environment. Specifically, the recipe for maximizing the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"long term reward\"), \" is discovered through learning.\"), mdx(\"h2\", null, \"Libraries for RL\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://juliareinforcementlearning.org/\"\n  }, \"JuliaReinforcementLearningDiscourse_logo\"))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"","private":false},"outboundReferences":[{"contextLine":"Teaching an [[agent]] to maximize a [[reward]] from actioning on the environment. Specifically, the recipe for maximizing the *long term reward* is discovered through learning.","targetAnchor":null,"refWord":"agent","target":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"agent\"), mdx(\"p\", null, \"An entity that \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"acts\"), \" on an environment based on observations.\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"id":"37f8694d-2799-56cc-8802-48acb2644d11","fields":{"slug":"/notes/agent","title":"agent"}}}}],"inboundReferences":[{"contextLine":"Monte Carlo Tree Search, used in [[reinforcement learning]].","referrer":{"parent":{"id":"4111bb1d-7e62-5758-ba3d-015e0baee975","fields":{"slug":"/notes/mcts","title":"mcts"}}}},{"contextLine":"In the context of [[reinforcement learning]], according to [[decision-making-book]] uncertainty comprises:","referrer":{"parent":{"id":"bd86e722-d930-5c0d-8e57-d72278691df5","fields":{"slug":"/notes/uncertainty","title":"uncertainty"}}}},{"contextLine":"- [[reinforcement learning]]","referrer":{"parent":{"id":"be8ae56f-15a1-5eec-9f16-43ec9bc7a323","fields":{"slug":"/readme","title":"ML Reviews"}}}}]},"fields":{"slug":"/notes/reinforcement learning","title":"reinforcement learning"}}},"pageContext":{"id":"7988b0fc-1c00-560f-87fc-0fdbe7cb33f2","refWordMdxSlugDict":{"agent":"notes/agent"}}},
    "staticQueryHashes": ["2221750479","2380733210","2768355698","63159454","847517413"]}