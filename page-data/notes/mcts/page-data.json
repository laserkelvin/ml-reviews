{
    "componentChunkName": "component---node-modules-gatsby-theme-kb-src-templates-topic-js",
    "path": "/notes/mcts",
    "result": {"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"mcts\"), mdx(\"p\", null, \"Monte Carlo Tree Search, used in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reinforcement-learning\",\n    \"title\": \"reinforcement learning\"\n  }, \"[[reinforcement learning]]\"), \".\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.informs-sim.org/wsc18papers/includes/files/021.pdf\"\n  }, \"Here's a great comprehensive piece on the concept.\")), mdx(\"p\", null, \"[reinforcement learning]\", \": reinforcement learning \\\"reinforcement learning\\\"\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"","private":false},"outboundReferences":[{"contextLine":"Monte Carlo Tree Search, used in [[reinforcement learning]].","targetAnchor":null,"refWord":"reinforcement learning","target":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"reinforcement learning\"), mdx(\"p\", null, \"Teaching an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"agent\",\n    \"title\": \"agent\"\n  }, \"[[agent]]\"), \" to maximize a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reward\",\n    \"title\": \"reward\"\n  }, \"[[reward]]\"), \" from actioning on the environment. Specifically, the recipe for maximizing the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"long term reward\"), \" is discovered through learning.\"), mdx(\"h2\", null, \"Libraries for RL\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://juliareinforcementlearning.org/\"\n  }, \"JuliaReinforcementLearningDiscourse_logo\"))));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"id":"7988b0fc-1c00-560f-87fc-0fdbe7cb33f2","fields":{"slug":"/notes/reinforcement learning","title":"reinforcement learning"}}}}],"inboundReferences":[]},"fields":{"slug":"/notes/mcts","title":"mcts"}}},"pageContext":{"id":"4111bb1d-7e62-5758-ba3d-015e0baee975","refWordMdxSlugDict":{"reinforcement learning":"notes/reinforcement-learning","agent":"notes/agent"}}},
    "staticQueryHashes": ["2221750479","2380733210","2768355698","63159454","847517413"]}