{
    "componentChunkName": "component---node-modules-gatsby-theme-kb-src-templates-topic-js",
    "path": "/notes/bayesian-neural-networks",
    "result": {"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"bayesian-neural-networks\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/neural-networks\",\n    \"title\": \"neural networks\"\n  }, \"[[neural networks]]\"), \" in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/bayesian\",\n    \"title\": \"bayesian\"\n  }, \"[[bayesian]]\"), \" formalism. The general idea is that the initialization schemes for neural networks act as priors, and by training the network, we end up with a parameterized \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/posterior-distribution\",\n    \"title\": \"posterior distribution\"\n  }, \"[[posterior distribution]]\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"","private":false},"outboundReferences":[],"inboundReferences":[{"contextLine":"Is a sub-category of [[bayesian-neural-networks]], whereby variational inference is done, usually in contrast to full [[MCMC]] sampling.","referrer":{"parent":{"id":"0dff8916-86db-5c4c-bdee-c0c7be1cb322","fields":{"slug":"/notes/variational autoencoder","title":"variational autoencoder"}}}},{"contextLine":"- Not to be confused with [[bayesian-neural-networks]], this type of model is basically analogous to a [[decision-tree]], albeit as a directed acyclic [[graph]].","referrer":{"parent":{"id":"a47525cc-f6dc-5ef7-9215-50f03cdf6bf6","fields":{"slug":"/notes/bayesian-network","title":"bayesian-network"}}}},{"contextLine":"- A deep ensemble is supposed to be easier to implement and train than [[bayesian-neural-networks]], either variational or MCMC.","referrer":{"parent":{"id":"3f62869b-c6df-5c74-bc98-e7fcbbfb615d","fields":{"slug":"/notes/scalable-uncertainties-from-deep-ensembles","title":"scalable-uncertainties-from-deep-ensembles"}}}}]},"fields":{"slug":"/notes/bayesian-neural-networks","title":"bayesian-neural-networks"}}},"pageContext":{"id":"f9da958d-5c93-5082-898e-0f3d0a4b0dd1","refWordMdxSlugDict":{}}},
    "staticQueryHashes": ["2221750479","2380733210","2768355698","63159454","847517413"]}