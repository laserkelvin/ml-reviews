{
    "componentChunkName": "component---node-modules-gatsby-theme-kb-src-templates-topic-js",
    "path": "/notes/uncertainty",
    "result": {"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"uncertainty\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"#aleatoric uncertainty is statistical uncertainty, i.e. in the frequentist view noisy measurements.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"#epistemic uncertainty is systematic uncertainty, i.e. model aspects not considered, such as physical constraints like gravity, etc.\")), mdx(\"h2\", null, \"Reinforcement learning\"), mdx(\"p\", null, \"In the context of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"reinforcement%20learning\",\n    \"title\": \"reinforcement learning\"\n  }, \"[[reinforcement learning]]\"), \", according to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/decision-making-book\",\n    \"title\": \"decision-making-book\"\n  }, \"[[decision-making-book]]\"), \" uncertainty comprises:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"outcome uncertainty\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"what effect will our action have\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"model uncertainty\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"our model of the problem is uncertain\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"state uncertainty\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the true state is uncertain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"can be modelled as a \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/partially-observable-markov-decision-process\",\n    \"title\": \"partially-observable-markov-decision-process\"\n  }, \"[[partially-observable-markov-decision-process]]\"), \"\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"interaction uncertainty\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"behavior of other agents is uncertain\")))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"","private":false},"outboundReferences":[{"contextLine":"In the context of [[reinforcement learning]], according to [[decision-making-book]] uncertainty comprises:","targetAnchor":null,"refWord":"reinforcement learning","target":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"reinforcement learning\"), mdx(\"p\", null, \"Teaching an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"agent\",\n    \"title\": \"agent\"\n  }, \"[[agent]]\"), \" to maximize a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/reward\",\n    \"title\": \"reward\"\n  }, \"[[reward]]\"), \" from actioning on the environment. Specifically, the recipe for maximizing the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"long term reward\"), \" is discovered through learning.\"), mdx(\"h2\", null, \"Libraries for RL\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://juliareinforcementlearning.org/\"\n  }, \"JuliaReinforcementLearningDiscourse_logo\"))));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"id":"7988b0fc-1c00-560f-87fc-0fdbe7cb33f2","fields":{"slug":"/notes/reinforcement learning","title":"reinforcement learning"}}}}],"inboundReferences":[{"contextLine":"A probabilistic [[architecture]] from the family of [[autoencoders]]. The self-learned representation is used to parameterize a probability distribution (i.e. the [[posterior distribution]]), from which a decoder can draw samples from to generate a range of outputs. We can either directly predict the mean of the distribution, or perform sampling over the distribution to obtain #uncertainty estimates.","referrer":{"parent":{"id":"0dff8916-86db-5c4c-bdee-c0c7be1cb322","fields":{"slug":"/notes/variational autoencoder","title":"variational autoencoder"}}}}]},"fields":{"slug":"/notes/uncertainty","title":"uncertainty"}}},"pageContext":{"id":"bd86e722-d930-5c0d-8e57-d72278691df5","refWordMdxSlugDict":{"reinforcement learning":"notes/reinforcement-learning","agent":"notes/agent"}}},
    "staticQueryHashes": ["2221750479","2380733210","2768355698","63159454","847517413"]}