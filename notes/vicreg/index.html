<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/ml-reviews/styles.cd26d764ef9aba2e9aa1.css" id="gatsby-global-css">.popover{position:relative;max-width:16rem;box-shadow:0 10px 15px -3px var(--shadow),0 4px 6px -2px rgba(0,0,0,.05);padding:1rem;border:1px solid var(--separator);border-radius:.5rem;background-color:var(--references-bg);max-height:16rem;overflow:hidden}.popover.no-max-width{max-width:90vw}.popover.with-markdown{font-size:.875rem}.popover h1{margin:0;padding:0;font-size:1rem}.popover ul{padding-left:1rem}.popover .more-content-blind{height:4rem;position:absolute;background:transparent;background:linear-gradient(0,var(--references-bg),var(--references-bg-80) 50%,var(--references-bg-0));top:12rem;width:100%;left:0}.tippy-box[data-animation=shift-away][data-state=hidden]{opacity:0}.tippy-box[data-animation=shift-away][data-state=hidden][data-placement^=top]{-webkit-transform:translateY(10px);transform:translateY(10px)}.tippy-box[data-animation=shift-away][data-state=hidden][data-placement^=bottom]{-webkit-transform:translateY(-10px);transform:translateY(-10px)}.tippy-box[data-animation=shift-away][data-state=hidden][data-placement^=left]{-webkit-transform:translateX(10px);transform:translateX(10px)}.tippy-box[data-animation=shift-away][data-state=hidden][data-placement^=right]{-webkit-transform:translateX(-10px);transform:translateX(-10px)}.reference{text-decoration:none}.reference:hover{color:var(--references-highlight)}.reference>div{padding-top:.5rem;padding-bottom:.5rem}.reference>div>p{margin:0;font-size:.875rem}.reference>div>ul{margin:0}.references-block{color:var(--references-text);padding:1rem;margin:1rem 0;border-radius:.5rem;background-color:var(--references-bg);transition:background-color .3s ease,color .3s ease}.references-block>div{margin-bottom:1rem}.references-block>hr{margin-left:auto;margin-right:auto;width:8rem}.references-block a{color:var(--references-text);transition:color .3s ease}.references-block>p:last-child{margin-bottom:0}.note-container{background:var(--note-bg);transition:background .3s ease}.note-container:first-child{border-left:none}.note-container .note-content,.note-container .obstructed-label{transition:opacity 75ms linear}.note-container .obstructed-label{display:block;color:var(--text);text-decoration:none;font-size:17px;line-height:40px;font-weight:500;-webkit-writing-mode:vertical-lr;-ms-writing-mode:tb-lr;writing-mode:vertical-lr;-webkit-text-orientation:sideways;text-orientation:sideways;margin-top:36px;top:0;bottom:0;left:0;position:absolute;background-color:transparent;width:40px;overflow:hidden;opacity:0;transition:color .3s ease;pointer-events:none}.note-container.note-container-highlighted{background:var(--references-bg);transition:background .3s ease}.note-content img{max-width:100%}@media screen and (max-width:800px){.note-container{padding:16px;width:100%;overflow-y:auto}}@media screen and (min-width:801px){.note-container{transition:box-shadow .1s linear,opacity 75ms linear,-webkit-transform .2s cubic-bezier(.19,1,.22,1);transition:box-shadow .1s linear,opacity 75ms linear,transform .2s cubic-bezier(.19,1,.22,1);transition:box-shadow .1s linear,opacity 75ms linear,transform .2s cubic-bezier(.19,1,.22,1),-webkit-transform .2s cubic-bezier(.19,1,.22,1);flex-shrink:0;width:625px;max-width:625px;top:0;position:sticky;flex-grow:1;border-left:1px solid var(--separator);padding:0}.note-content{overflow-y:auto;height:100%;padding:32px}.note-container-overlay{box-shadow:0 0 15px 3px var(--shadow)}.note-container-obstructed .note-content{opacity:0}.note-container-obstructed .obstructed-label{opacity:1;pointer-events:all}}.dark-mode-toggle{cursor:pointer;-webkit-transform:scale(.6);transform:scale(.6)}.dark-mode-toggle input{display:none}.dark-mode-toggle input+div{border-radius:50%;width:36px;height:36px;position:relative;box-shadow:inset 16px -16px 0 0 #fff;-webkit-transform:scale(1) rotate(-2deg);transform:scale(1) rotate(-2deg);transition:box-shadow .5s ease 0s,-webkit-transform .4s ease .1s;transition:box-shadow .5s ease 0s,transform .4s ease .1s;transition:box-shadow .5s ease 0s,transform .4s ease .1s,-webkit-transform .4s ease .1s}.dark-mode-toggle input+div:before{content:"";width:inherit;height:inherit;border-radius:inherit;position:absolute;left:0;top:0;transition:background .3s ease}.dark-mode-toggle input+div:after{content:"";width:8px;height:8px;border-radius:50%;margin:-4px 0 0 -4px;position:absolute;top:50%;left:50%;box-shadow:0 -23px 0 var(--link),0 23px 0 var(--link),23px 0 0 var(--link),-23px 0 0 var(--link),15px 15px 0 var(--link),-15px 15px 0 var(--link),15px -15px 0 var(--link),-15px -15px 0 var(--link);-webkit-transform:scale(0);transform:scale(0);transition:all .3s ease}.dark-mode-toggle input:checked+div{box-shadow:inset 32px -32px 0 0 #fff;-webkit-transform:scale(.5) rotate(0deg);transform:scale(.5) rotate(0deg);transition:box-shadow .2s ease 0s,-webkit-transform .3s ease .1s;transition:transform .3s ease .1s,box-shadow .2s ease 0s;transition:transform .3s ease .1s,box-shadow .2s ease 0s,-webkit-transform .3s ease .1s}.dark-mode-toggle input:checked+:before{background:var(--link);transition:background .3s ease .1s}.dark-mode-toggle input:checked+:after{-webkit-transform:scale(1.5);transform:scale(1.5);transition:-webkit-transform .5s ease .15s;transition:transform .5s ease .15s;transition:transform .5s ease .15s,-webkit-transform .5s ease .15s}.graph-button{border:0;background:none;cursor:pointer}.graph-button svg g{stroke:var(--link)}.searchWrapper{position:relative;display:block}.inputWrapper{position:relative;color:var(--text)}.inputWrapper .searchIcon{position:absolute;fill:var(--link);left:2px;height:34px;padding:2px 2px 0;pointer-events:none}.inputWrapper input{color:var(--text);font-size:1rem;border:none;height:36px;padding-left:28px;background-color:var(--note-bg);transition:all .3s ease-in-out;width:28px}.inputWrapper input:focus{outline:none;width:100%}.results{-webkit-padding-start:0;padding-inline-start:0;position:absolute;display:block;top:100%;right:0;width:500px;max-height:50vh;background:var(--note-bg);box-shadow:-5px -5px 15px -3px var(--shadow),0 4px 6px -2px rgba(0,0,0,.05);overflow-y:auto;border-radius:8px}.results li{display:block;text-decoration:none;cursor:pointer;padding:16px 24px;border-bottom:1px solid var(--separator)}.results li:hover{background:var(--references-bg)}.results li .title{color:var(--text)}.results li .excerpt{color:var(--references-text)}@media screen and (max-width:600px){.results{right:-85px;width:calc(100vw - 40px)}}.lds-dual-ring:after{content:" ";left:calc(50% - 32px);position:relative;display:block;width:64px;height:64px;margin:8px;border-radius:50%;border-color:var(--separator);border-left:6px solid transparent;border-bottom:6px solid var(--separator);border-right:6px solid transparent;border-top:6px solid var(--separator);-webkit-animation:lds-dual-ring 1.2s ease-in-out infinite;animation:lds-dual-ring 1.2s ease-in-out infinite}@-webkit-keyframes lds-dual-ring{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes lds-dual-ring{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}header{width:100%;min-height:57px;z-index:5;background-color:var(--note-bg);border-bottom:1px solid var(--separator);display:flex;justify-content:space-between;align-items:center;padding:10px 32px;flex-wrap:wrap;transition:background-color .3s ease}header>a{font-weight:700;color:var(--text);text-decoration:none;transition:color .3s ease}header .controls{display:flex}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}body.light-mode{--main-bg:#fafafc;--note-bg:#fff;--text:#1a202c;--separator:#e2e8f0;--shadow:rgba(0,0,0,0.1);--link:#3182ce;--references-bg:#ebf4ff;--references-bg-80:rgba(235,244,255,0.8);--references-bg-0:rgba(235,244,255,0);--references-text:#718096;--references-highlight:#4a5568}body.dark-mode{--main-bg:#000;--note-bg:#0a0d11;--text:#fafafc;--separator:#252525;--shadow:hsla(0,0%,100%,0.1);--link:#3da1ff;--references-bg:#17181a;--references-bg-80:rgba(23,24,26,0.8);--references-bg-0:rgba(23,24,26,0);--references-text:#8c9fbb;--references-highlight:#b3cbf0}body{background-color:var(--main-bg);color:var(--text);margin:0;padding:0;height:100vh;transition:background-color .3s ease,color .3s ease}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,p,pre{margin:0}*,:after,:before{box-sizing:border-box}h1,h2,h3{font-weight:700}hr{margin-top:1rem;margin-bottom:1rem;border:solid var(--separator);border-width:1px 0 0;box-sizing:content-box;height:0;overflow:visible}a{color:var(--link);text-decoration:underline;transition:color .3s ease}a:hover{text-decoration:none}h1{font-size:1.875rem;margin-top:1rem}h1,p{margin-bottom:1rem}.layout{height:100vh;display:flex;flex-direction:column}.note-columns-scrolling-container{display:flex;overflow-x:auto;overflow-y:hidden;flex-grow:1}.note-columns-container{display:flex;flex-grow:1;transition:width .1s cubic-bezier(.19,1,.22,1)}@media screen and (max-width:800px){.note-columns-container{width:unset!important}}.overlay{z-index:98;position:fixed;top:0;right:0;bottom:0;left:0;display:flex;align-items:center;justify-content:center;height:100%;width:100%;background-color:var(--shadow);-webkit-backdrop-filter:blur(4px);backdrop-filter:blur(4px)}.modal{z-index:99;position:fixed;border-radius:8px;background-color:var(--main-bg);box-shadow:-5px -5px 15px -3px var(--shadow),0 4px 6px -2px rgba(0,0,0,.05)}.modal-close,.modal-scale{position:absolute;top:0;right:0;padding:5px;border:0;background:none;color:var(--text);cursor:pointer}.modal-close svg,.modal-scale svg{width:20px;height:20px}.modal-close path,.modal-scale path{fill:currentColor}.modal-scale{right:30px}.modal-minimized .modal-close svg,.modal-minimized .modal-scale svg{width:15px;height:15px}.modal-minimized .modal-scale{right:25px}.modal-body{height:100%;width:100%}.modal-body .node,.modal-body .text{cursor:pointer}</style><meta name="generator" content="Gatsby 2.32.13"/><link as="script" rel="preload" href="/ml-reviews/component---node-modules-gatsby-theme-garden-src-templates-local-file-js-3b9589dd09f01601b550.js"/><link as="script" rel="preload" href="/ml-reviews/styles-407fe62976dc5310c43e.js"/><link as="script" rel="preload" href="/ml-reviews/app-17813d5b57bc1865e53c.js"/><link as="script" rel="preload" href="/ml-reviews/framework-06f646d936b841f99ebd.js"/><link as="script" rel="preload" href="/ml-reviews/webpack-runtime-5218c8947c305be24218.js"/><link as="fetch" rel="preload" href="/ml-reviews/page-data/notes/vicreg/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/ml-reviews/page-data/sq/d/2098632890.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/ml-reviews/page-data/sq/d/2221750479.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/ml-reviews/page-data/sq/d/2468095761.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/ml-reviews/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="layout"><header><a href="/ml-reviews/"><h3>ML Reviews</h3></a><div class="controls"><div class="searchWrapper" role="combobox" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="downshift-36-label"><div class="inputWrapper"><svg class="searchIcon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M23.111 20.058l-4.977-4.977c.965-1.52 1.523-3.322 1.523-5.251 0-5.42-4.409-9.83-9.829-9.83-5.42 0-9.828 4.41-9.828 9.83s4.408 9.83 9.829 9.83c1.834 0 3.552-.505 5.022-1.383l5.021 5.021c2.144 2.141 5.384-1.096 3.239-3.24zm-20.064-10.228c0-3.739 3.043-6.782 6.782-6.782s6.782 3.042 6.782 6.782-3.043 6.782-6.782 6.782-6.782-3.043-6.782-6.782z"></path></svg><input type="text" aria-autocomplete="list" aria-labelledby="downshift-36-label" autoComplete="off" value="" id="downshift-36-input" placeholder="Search..."/></div></div><button title="Show Graph visualisation" aria-label="Show Graph visualisation" class="graph-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20"><g fill="none" stroke-width="2"><circle cx="11.733" cy="3.181" r="1.902"></circle><circle cx="16.864" cy="10.861" r="1.902"></circle><circle cx="7.47" cy="16.822" r="1.902"></circle><circle cx="3.046" cy="6.275" r="1.902"></circle><circle cx="9.372" cy="10.861" r="1.902"></circle><line x1="11.635" x2="14.655" y1="10.861" y2="10.861"></line><line x1="10" x2="10.895" y1="8.959" y2="5.573"></line><line x1="7.47" x2="4.5" y1="9.68" y2="7.5"></line><line x1="8.25" x2="8.809" y1="14.92" y2="13.088"></line></g></svg></button><label class="dark-mode-toggle" aria-label="Activate dark mode" title="Activate dark mode"><input type="checkbox" checked=""/><div></div></label></div></header><div class="note-columns-scrolling-container"><div class="note-columns-container" style="width:1250px"><div class="note-container   " style="left:0;right:-585px"><div class="note-content"><h1 id="vicreg-variance-invariance-covariance-regularization-for-self-supervised-learning">vicreg: Variance-invariance-covariance regularization for self-supervised learning</h1><h2 id="arxiv"><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2105.04906">arxiv</a></h2><p><em>First written</em>: Sep/03/2021, 09:20:52</p><h2 id="summary">Summary</h2><ul><li>Un/self-supervised learning of representations is difficult: embeddings can likely end up with highly correlated features<sup id="fnref-1"><a class="footnote-ref" href="#fn-1">1</a></sup><ul><li>We also want to preserve the idea that similar inputs should result in similar encodings, with the most straightforward result being the same embedding regardless of inputs (i.e. a <em>collapse</em>). This also involves some clustering heuristic that might not be simple.</li></ul></li><li>Conventionally, good embeddings can be obtained through <a href="/ml-reviews/contrastive-learning" title="contrastive-learning">[[contrastive-learning]]</a>, forcing dissimilar inputs to have different embeddings, and vice versa<ul><li>Contrastive learning is expensive, however, because to do it well you have to find examples and counterexamples during training; e.g. <a href="/ml-reviews/triplet-loss" title="triplet-loss">[[triplet-loss]]</a> variants.</li></ul></li><li>VICReg encodes three heuristics as a form of regularization: variance, invariance, and covariance</li></ul><h2 id="useful-embeddings">Useful embeddings</h2><ul><li>The requirements typically are:<ul><li>Similar inputs -&gt; similar embeddings (i.e. clustering)</li><li>Dissimilar inputs -&gt; dissimilar embeddings (i.e. contrast)</li></ul></li></ul><h2 id="vic-regularization">VIC regularization</h2><blockquote><p>...the architecture is completely symmetric and consists of an encoder $f<em>\theta$ that outputs the final representations, followed by a project $h</em>\phi$ that maps the representations into projections in a embedding space where the loss function will be computed.</p></blockquote><ul><li>Projector gets rid of low-level information in the representations, and is only used for computing the loss (i.e. not used for actual tasks)</li></ul><h3 id="notation">Notation</h3><table><thead><tr><th>Symbol</th><th>Meaning</th></tr></thead><tbody><tr><td>$Z$, $Z&#x27;$</td><td>Batch of embeddings, for either network</td></tr><tr><td>$Y$</td><td>The representation used for tasks</td></tr><tr><td>$n$</td><td>Batch size</td></tr><tr><td>$d$</td><td>Embedding dimensionality</td></tr><tr><td>$v$</td><td>Variance (regularization)</td></tr><tr><td>$\epsilon$</td><td>Small scalar for stability</td></tr></tbody></table><h3 id="architecture">Architecture</h3><p><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:561px">
      <a class="gatsby-resp-image-link" style="display:block" href="/ml-reviews/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/09e48/2021-09-03-09-42-34.png">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:56.42857142857143%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB0UlEQVQoz11SiZKiQAzl/z/N8liVy3F0ALmhOQRUPHiTRHGtSVU63bnzOhpeNAwDPmkYHiL7/oLj8YjHfXj7nc9n5HmOKIrQti2ut9vbpvExJmuaBq7r4XTq4MUKtpsiTnMkSYx9uIETb1FWJeqqxnw+x2w6Jd8T6roWKQnHzNwFV/ze7dBSYifMYOxDFNVRAr59E1+ejqqucL1esd1ucTgcpJHH44GxMY0TOY7zHIsMI1/OJy71DLhTACFw6++SjO1FUaCqKhn5EzatLEupxuNy277vi1OUlTL2sWmlwzDzEKsATdvgRpjpuo71ei13juv7/pmQFQwyB0VhiB2NXBFO+yDDv22AMMmhVI4vfw39ZwZV5OK/Wq1gWZZ03HUdLpfLfww/icd5tv9H//r1kTgpY83ykzQej1tmPLIsE2xypVARFIokvxmWkXld2JfvimxsT9MUGTHn0TzXhWmaMAwDi8UCk8lE3rZty5uxmtJ68JoYpNf1tWDHPJ/NMCM929k3SRJoPn09BxmGjuVyKcn4vdlsCCMbJhXiYC5oWabYpQHyYQxt23o3pFQBLctSWpsfeJ4n6xMEAf30ge6urJJgRaCz5JFG2b10zHxnHX/QL/oHPYhEOSSBAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="2021 09 03 09 42 34" title="2021 09 03 09 42 34" src="/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/410f3/2021-09-03-09-42-34.png" srcSet="/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/0d3e1/2021-09-03-09-42-34.png 140w,/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/6b1e2/2021-09-03-09-42-34.png 281w,/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/410f3/2021-09-03-09-42-34.png 561w,/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/99072/2021-09-03-09-42-34.png 842w,/ml-reviews/static/d8ad198cf77bbf9ec343d435da74a77c/09e48/2021-09-03-09-42-34.png 974w" sizes="(max-width: 561px) 100vw, 561px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
  </a>
    </span></p><h3 id="variance">Variance</h3><p>The variance regularization term is given by a <a href="/ml-reviews/hinge-loss" title="hinge-loss">[[hinge-loss]]</a>:</p><p>$$ v(Z) = \frac{1}{d}\sum<em>{j=1}^{d}\max(0, \gamma - \sqrt{\mathrm{Var}(Z</em>{:,j}) + \epsilon}) $$</p><p>where $\gamma$ is a target value for the standard deviation (fixed to one for this paper)<sup id="fnref-2"><a class="footnote-ref" href="#fn-2">2</a></sup>, and $\mathrm{Var}(x)$ is the variance estimator:</p><p>$$\mathrm{Var}(x) = \frac{1}{n - 1}\sum_{i=1}^n(x_i - \bar{x})^2$$</p><p>This forces the variance in a batch of embeddings to be $\gamma$ along each dimension.</p><h3 id="covariance">Covariance</h3><p>The covariance of matrix $Z$ is given as:</p><p>$$C(Z) = \frac{1}{n - 1}\sum_{i=1}^n(Z_i - \bar{Z})(Z_i - \bar{Z})^T$$</p><p>with $\bar{Z}$ being the mean embedding across a batch. The actual covariance loss term is taken as the squared off-diagonal coefficients of $C$ that scales with dimensionality $1/d$:</p><p>$$c(Z) = \frac{1}{d}\sum<em>{i\neq j}C(Z)^2</em>{i,j}$$</p><p>So that we force the embeddings to learn unit Gaussians similar to the $\beta$-regularization in <a title="variational autoencoder" href="/ml-reviews/notes/variational autoencoder">[[variational autoencoder]]</a>.</p><h3 id="invariance">Invariance</h3><p>The invariance loss is given by:</p><p>$$s(Z,Z&#x27;) = \frac{1}{n}\sum_i \vert\vert Z_i - Z&#x27;_i \vert\vert ^2_2$$</p><p>i.e. the mean squared Euclidean distance between each network embedding pair.</p><ul><li>This encourages the model to learn the same upstream representation for nominally the same input.</li></ul><h3 id="the-full-loss">The full loss</h3><p>$$l(Z,Z&#x27;) = \lambda s(Z,Z&#x27;) + \mu<!-- -->{<!-- -->v(Z) + v(Z&#x27;)<!-- -->}<!-- --> + v<!-- -->{<!-- -->c(Z) + c(Z&#x27;)<!-- -->}<!-- --> $$</p><p>with hyperparameters $\lambda$, $\mu$, and $\nu$.</p><h2 id="comments">Comments</h2><p>[variational autoencoder]<!-- -->: variational autoencoder &quot;variational autoencoder&quot;</p><div class="footnotes"><hr/><ol><li id="fn-1">If they&#x27;re correlated, you are not using each dimension as effectively as you <em>could</em>.<a class="footnote-backref" href="#fnref-1">↩</a></li><li id="fn-2">Might be worth seeing how this changes stuff<a class="footnote-backref" href="#fnref-2">↩</a></li></ol></div></div><a aria-current="page" class="obstructed-label" href="/ml-reviews/notes/vicreg">vicreg: Variance-invariance-covariance regularization for self-supervised learning</a></div></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/notes/vicreg";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-b26ca15045427b9506aa.js"],"app":["/app-17813d5b57bc1865e53c.js"],"component---node-modules-gatsby-theme-garden-src-templates-local-file-js":["/component---node-modules-gatsby-theme-garden-src-templates-local-file-js-3b9589dd09f01601b550.js"]};/*]]>*/</script><script src="/ml-reviews/polyfill-b26ca15045427b9506aa.js" nomodule=""></script><script src="/ml-reviews/webpack-runtime-5218c8947c305be24218.js" async=""></script><script src="/ml-reviews/framework-06f646d936b841f99ebd.js" async=""></script><script src="/ml-reviews/app-17813d5b57bc1865e53c.js" async=""></script><script src="/ml-reviews/styles-407fe62976dc5310c43e.js" async=""></script><script src="/ml-reviews/component---node-modules-gatsby-theme-garden-src-templates-local-file-js-3b9589dd09f01601b550.js" async=""></script></body></html>