{"be8ae56f-15a1-5eec-9f16-43ec9bc7a323":{"id":"be8ae56f-15a1-5eec-9f16-43ec9bc7a323","path":"/readme","title":"ML Reviews","excerpt":"ML Reviews Welcome to ML Reviews: a Zettelkasten for learning about machine learning methodologies. Primarily, I've been writing notes for…"},"b5fea67c-16e7-5826-95ab-562ecbd7bf27":{"id":"b5fea67c-16e7-5826-95ab-562ecbd7bf27","path":"/notes/Adversarial training","title":"Adversarial training","excerpt":"Adversarial training Training examples given to a model that are  close  to the original training examples - i.e. perturbations that are…"},"37f8694d-2799-56cc-8802-48acb2644d11":{"id":"37f8694d-2799-56cc-8802-48acb2644d11","path":"/notes/agent","title":"agent","excerpt":"agent An entity that  acts  on an environment based on observations."},"a4f94698-6ed6-5e36-bae3-d4b2fc873702":{"id":"a4f94698-6ed6-5e36-bae3-d4b2fc873702","path":"/notes/autoencoders","title":"autoencoders","excerpt":"autoencoders A type of machine learning [architecture] that encodes data into a self-learned representation."},"63acb363-e8be-5def-b59f-b9c2a03f605b":{"id":"63acb363-e8be-5def-b59f-b9c2a03f605b","path":"/notes/bayes-rule","title":"bayes-rule","excerpt":"bayes-rule Canonically, for events   and  , we have the definition: where   is the [evidence],   is the [prior],   is the [ posterior…"},"25af8dd6-df00-514a-9ea6-870c030d95c8":{"id":"25af8dd6-df00-514a-9ea6-870c030d95c8","path":"/notes/bayesian-network-scoring","title":"bayesian-network-scoring","excerpt":"bayesian-network-scoring This is basically model selection, for [bayesian-network] models. The idea is to infer the probability   for…"},"a47525cc-f6dc-5ef7-9215-50f03cdf6bf6":{"id":"a47525cc-f6dc-5ef7-9215-50f03cdf6bf6","path":"/notes/bayesian-network","title":"bayesian-network","excerpt":"bayesian-network Definition Not to be confused with [bayesian-neural-networks], this type of model is basically analogous to a [ decision…"},"f9da958d-5c93-5082-898e-0f3d0a4b0dd1":{"id":"f9da958d-5c93-5082-898e-0f3d0a4b0dd1","path":"/notes/bayesian-neural-networks","title":"bayesian-neural-networks","excerpt":"bayesian-neural-networks [ neural networks ] in a [bayesian] formalism. The general idea is that the initialization schemes for neural…"},"07de1c18-ea5d-5731-893b-da0b7c7cd099":{"id":"07de1c18-ea5d-5731-893b-da0b7c7cd099","path":"/notes/bayesian-parameter-estimation","title":"bayesian-parameter-estimation","excerpt":"bayesian-parameter-estimation Obtain an estimate for parameters   given data  , by integrating over the full parameter space and evaluating…"},"7ca8c2f2-c1d0-572b-8d78-fa6647aee34b":{"id":"7ca8c2f2-c1d0-572b-8d78-fa6647aee34b","path":"/notes/boosting","title":"boosting","excerpt":"boosting"},"2f65aaaf-a79f-5aa4-bc1c-5f91664bcfb4":{"id":"2f65aaaf-a79f-5aa4-bc1c-5f91664bcfb4","path":"/notes/conda","title":"conda","excerpt":"conda Commonly used commands Make environment from  conda.yml  specification conda env create -f conda.yml Export environment from  conda…"},"4b6e0da8-33e0-5618-acf9-96d0b38159f6":{"id":"4b6e0da8-33e0-5618-acf9-96d0b38159f6","path":"/notes/conditional-distribution","title":"conditional-distribution","excerpt":"conditional-distribution A [probability-distribution] related to the [marginal-distribution], as the possible values of one variable…"},"1a4918cb-1041-5778-b327-0067bf8ca602":{"id":"1a4918cb-1041-5778-b327-0067bf8ca602","path":"/notes/cyclical-annealing-schedule-a-simple-approach-to-mitigating-kl-vanishing","title":"cyclical-annealing-schedule-a-simple-approach-to-mitigating-kl-vanishing","excerpt":"cyclical-annealing-schedule-a-simple-approach-to-mitigating-kl-vanishing arxiv First written : Aug/20/2021, 14:40:22 Summary Comments…"},"7a14959b-43cf-5833-a6be-57b02693badb":{"id":"7a14959b-43cf-5833-a6be-57b02693badb","path":"/notes/decision-theory","title":"decision-theory","excerpt":"decision-theory Must be acyclic, directed graphs like [bayesian-network]. Notation Expression Description Prefer   over  Indifference over…"},"e8b4b47a-9edd-5123-9f99-5ca526838a73":{"id":"e8b4b47a-9edd-5123-9f99-5ca526838a73","path":"/notes/decision-tree","title":"decision-tree","excerpt":"decision-tree Storing joint probabilities From [decision-making-book], one way of storing joint discrete probabilities is with a decision…"},"3fa3f33f-498e-54e5-b13a-279f5cc23a03":{"id":"3fa3f33f-498e-54e5-b13a-279f5cc23a03","path":"/notes/distributions","title":"distributions","excerpt":"distributions Truncated Gaussian To #truncate a Gaussian: Mixture models From [decision-making-book]: ...a mixture model, which is a…"},"041bb2c7-ad81-564e-b1e3-bea95906f626":{"id":"041bb2c7-ad81-564e-b1e3-bea95906f626","path":"/notes/dl-parallelism","title":"dl-parallelism","excerpt":"dl-parallelism Parallelism in deep learning; check [hpc] for terminology Lots of stuff to unpack from  this link Data parallelism…"},"32ba8194-8f0f-5e41-b5f1-112d40dc041d":{"id":"32ba8194-8f0f-5e41-b5f1-112d40dc041d","path":"/notes/einstein-notation","title":"einstein-notation","excerpt":"einstein-notation Julia In Julia,  Tullio.jl  provides a high level interface for writing operations in Einstein notation. It adds a degree…"},"df73c168-fb55-5f88-a33a-f04f54aece64":{"id":"df73c168-fb55-5f88-a33a-f04f54aece64","path":"/notes/ensembles","title":"ensembles","excerpt":"ensembles Multiple models either with varying parameters or sees varied training data. Collectively, these sub-models learn parts of the…"},"5a4a663f-696a-5e37-9d70-15263d8eae41":{"id":"5a4a663f-696a-5e37-9d70-15263d8eae41","path":"/notes/evidence","title":"evidence","excerpt":"evidence This page is on the Bayesian evidence, with the notation  ; the probability of data   under model  . In an alternative way of…"},"eaa1e57a-3d0a-593b-a8fd-6e2fdedc963b":{"id":"eaa1e57a-3d0a-593b-a8fd-6e2fdedc963b","path":"/notes/fast gradient sign method","title":"fast gradient sign method","excerpt":"fast gradient sign method Given input   with target  , and loss function  , an adversarial example can be defined as  ."},"0d8051f0-dbc5-5ae9-a92d-85f55057d37d":{"id":"0d8051f0-dbc5-5ae9-a92d-85f55057d37d","path":"/notes/flux-notes","title":"flux-notes","excerpt":"flux-notes Batching Because Julia is column contiguous, the \"observation\" dimension is different from Python/ sklearn . We expect arrays to…"},"5eef8e6b-89b5-519b-ab7e-cf195c797509":{"id":"5eef8e6b-89b5-519b-ab7e-cf195c797509","path":"/notes/g2-spectra","title":"g2-spectra","excerpt":"g2-spectra Todo Change noise to be normalized to max of  true , not of noise. Make Gaussian noise less likely /date Forcing the latent…"},"59ce7294-db72-5db2-899b-9c142cafc1a0":{"id":"59ce7294-db72-5db2-899b-9c142cafc1a0","path":"/notes/gibbs-sampling","title":"gibbs-sampling","excerpt":"gibbs-sampling A derivative of [mcmc], where you ...draw samples consistent with the evidence in a way that does not involve weighting…"},"eede4f8b-09a3-5704-abe1-aaf219c98034":{"id":"eede4f8b-09a3-5704-abe1-aaf219c98034","path":"/notes/git-notes","title":"git-notes","excerpt":"git-notes A (useful) collection of Git commands From  this blogpost : Reverse a commit/push :  git revert <SHA> ; basically creates a new…"},"2ec65909-4902-5749-b849-132ca050257e":{"id":"2ec65909-4902-5749-b849-132ca050257e","path":"/notes/hardware","title":"hardware","excerpt":"hardware Intel [amx] instructions sound  pretty promising ."},"07c2ffd2-28b4-563c-97a6-0fb429473363":{"id":"07c2ffd2-28b4-563c-97a6-0fb429473363","path":"/notes/hpc","title":"hpc","excerpt":"hpc Terminology Here's a quick diagram to show the hierarchy:"},"c5abf820-bf82-52c9-aa48-467dd0de8e0c":{"id":"c5abf820-bf82-52c9-aa48-467dd0de8e0c","path":"/notes/julia-notes","title":"julia-notes","excerpt":"julia-notes LaTeX unicode \\scrS  for the fancy script   used in MDP states. Helpful cheatsheet to Julia commands Julia cheatsheet Useful…"},"aa00859d-5d25-5a7b-8a69-89320e12da6d":{"id":"aa00859d-5d25-5a7b-8a69-89320e12da6d","path":"/notes/kernel-density-estimation","title":"kernel-density-estimation","excerpt":"kernel-density-estimation A form of nonparametric modeling, where the number of parameters scales with the number of data points. Given…"},"1ed974ad-1472-5bac-bed1-16a6e73b18f5":{"id":"1ed974ad-1472-5bac-bed1-16a6e73b18f5","path":"/notes/linear-algebra-notes","title":"linear-algebra-notes","excerpt":"linear-algebra-notes Matrix factorization Equation Purpose Elimination Gram-Schmidt orthogonalization  eigenvalues,   eigenvectors SVD Four…"},"e99e275b-2424-5e26-b19a-7cd0f00550fd":{"id":"e99e275b-2424-5e26-b19a-7cd0f00550fd","path":"/notes/linear-gaussian-model","title":"linear-gaussian-model","excerpt":"linear-gaussian-model Described as a conditional distribution between two variables,   and  , as  , we can factor   as a linear function of…"},"a3284b79-7404-58d5-a25f-2f00a7eb59eb":{"id":"a3284b79-7404-58d5-a25f-2f00a7eb59eb","path":"/notes/lottery","title":"lottery","excerpt":"lottery A mapping between probabilities and outcomes. The mapping is written as probability ( )/outcome ( ) pairs;"},"e8a54739-a1b8-5710-9406-99e2c6e3a726":{"id":"e8a54739-a1b8-5710-9406-99e2c6e3a726","path":"/notes/machine-learning-notes","title":"machine-learning-notes","excerpt":"machine-learning-notes This is a collection of various, quasi random notes for machine learning topics from implementation to theory. [ dl…"},"29775e8f-242c-5678-b77b-99c9578e4d44":{"id":"29775e8f-242c-5678-b77b-99c9578e4d44","path":"/notes/marginal-distribution","title":"marginal-distribution","excerpt":"marginal-distribution A marginal distribution is determined by integrating over all other variables in a joint distribution: For the…"},"3565182e-1119-5de6-a08c-debc5ebf79d2":{"id":"3565182e-1119-5de6-a08c-debc5ebf79d2","path":"/notes/markov-decision-process","title":"markov-decision-process","excerpt":"markov-decision-process Decide to take action  , based on current state (only)  , for a reward  , comprising all possible states (which may…"},"2106e576-092d-5008-a756-3c47aa36a768":{"id":"2106e576-092d-5008-a756-3c47aa36a768","path":"/notes/maximum-a-posteriori","title":"maximum-a-posteriori","excerpt":"maximum-a-posteriori A point estimate of parameters   over dataset  , corresponding to the maximum of a posterior distribution  : i.e. the…"},"8651dfda-a629-5182-a44d-964a1ccf3820":{"id":"8651dfda-a629-5182-a44d-964a1ccf3820","path":"/notes/maximum-likelihood","title":"maximum-likelihood","excerpt":"maximum-likelihood For parameters  , and data  , the goal of maximum likelihood estimation is to evaluate: where   is also written as…"},"4111bb1d-7e62-5758-ba3d-015e0baee975":{"id":"4111bb1d-7e62-5758-ba3d-015e0baee975","path":"/notes/mcts","title":"mcts","excerpt":"mcts Monte Carlo Tree Search, used in [ reinforcement learning ]. Here's a great comprehensive piece on the concept. reinforcement learning…"},"c0eb38f6-e709-57d0-9fd0-98ddf97c804d":{"id":"c0eb38f6-e709-57d0-9fd0-98ddf97c804d","path":"/notes/ml-ops","title":"ml-ops","excerpt":"ml-ops Development of machine learning pipelines, from data to model training to deployment. The main ideas include [scalability] of…"},"3256b5de-0cc7-53e0-8499-8ca13799c18e":{"id":"3256b5de-0cc7-53e0-8499-8ca13799c18e","path":"/notes/model-evaluation","title":"model-evaluation","excerpt":"model-evaluation Splitting datasets From \"Pattern Recognition and Neural Networks\": – Training set: A set of examples used for learning…"},"8ea09812-a7de-5e9e-b476-23932d00c1fa":{"id":"8ea09812-a7de-5e9e-b476-23932d00c1fa","path":"/notes/negative log-likelihood","title":"negative log-likelihood","excerpt":"negative log-likelihood A metric for optimizing the log likelihood of a model; by minimizing the negative log likelihood, you maximize the…"},"e977ec3d-95ca-5d3f-9a7c-178fbb3e3d82":{"id":"e977ec3d-95ca-5d3f-9a7c-178fbb3e3d82","path":"/notes/nested-sampling","title":"nested-sampling","excerpt":"nested-sampling Sampling bounded shells of the hypothesis space, in order to efficiently compute the Bayesian [evidence]. The best way I…"},"841427c6-0412-519d-af64-8e3b9b3344d3":{"id":"841427c6-0412-519d-af64-8e3b9b3344d3","path":"/notes/node2vec","title":"node2vec","excerpt":"node2vec Method to generate node embeddings that encapsulate local neighborhood information, inspired from the  word2vec  model. Graph nodes…"},"087a4dbd-1e94-54b0-8dc1-5a0b4e04f226":{"id":"087a4dbd-1e94-54b0-8dc1-5a0b4e04f226","path":"/notes/policy","title":"policy","excerpt":"policy Concept in [decision-theory], specifically [markov-decision-process] For history   that accumulates all past states   and actions…"},"5fab5549-396c-5939-bbc5-6080810da2a0":{"id":"5fab5549-396c-5939-bbc5-6080810da2a0","path":"/notes/pomdp","title":"pomdp","excerpt":"pomdp Partially observable Markov Decision Processes A problem formulation that enable optimal sequential decisions to be made in uncertain…"},"568fb177-3b40-5259-99b5-3a6c253faa0f":{"id":"568fb177-3b40-5259-99b5-3a6c253faa0f","path":"/notes/posterior collapse","title":"posterior collapse","excerpt":"posterior collapse An issue primarily related to [ variational autoencoder ] models, where the output becomes deterministic in a supposedly…"},"aff8cb01-bccd-557b-a232-54efdcecb28d":{"id":"aff8cb01-bccd-557b-a232-54efdcecb28d","path":"/notes/recurrent-models","title":"recurrent-models","excerpt":"recurrent-models seq2seq Encoding RNN processes each timestep in  , and the last timestep corresponds to "},"7988b0fc-1c00-560f-87fc-0fdbe7cb33f2":{"id":"7988b0fc-1c00-560f-87fc-0fdbe7cb33f2","path":"/notes/reinforcement learning","title":"reinforcement learning","excerpt":"reinforcement learning Teaching an [agent] to maximize a [reward] from actioning on the environment. Specifically, the recipe for…"},"63e53be5-8f9a-5007-b4c0-c01d65512464":{"id":"63e53be5-8f9a-5007-b4c0-c01d65512464","path":"/notes/return","title":"return","excerpt":"return Another word for the sum of rewards in [markov-decision-process], with the goal of maximizing this (typically)."},"02a1d5c2-350e-5a94-97ba-1e3a0fc3f702":{"id":"02a1d5c2-350e-5a94-97ba-1e3a0fc3f702","path":"/notes/sampling-methods","title":"sampling-methods","excerpt":"sampling-methods [direct-sampling] [weighted-sampling] [gibbs-sampling]"},"3f62869b-c6df-5c74-bc98-e7fcbbfb615d":{"id":"3f62869b-c6df-5c74-bc98-e7fcbbfb615d","path":"/notes/scalable-uncertainties-from-deep-ensembles","title":"scalable-uncertainties-from-deep-ensembles","excerpt":"scalable-uncertainties-from-deep-ensembles arxiv First written : Aug/20/2021, 09:32:40 Summary While [ neural networks ] are good at a wide…"},"407fb1d4-b936-5a07-b418-60e84569c552":{"id":"407fb1d4-b936-5a07-b418-60e84569c552","path":"/notes/scoring rule","title":"scoring rule","excerpt":"scoring rule See: T. Gneiting and A. E. Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American…"},"a6bf0174-951c-508f-b037-00c03ac01aee":{"id":"a6bf0174-951c-508f-b037-00c03ac01aee","path":"/notes/snapshot-ensembles","title":"snapshot-ensembles","excerpt":"snapshot-ensembles arxiv First written : Nov/05/2021, 08:54:10 Summary Ensembling neural networks is a nominally expensive process, as…"},"1834c9ea-8b48-56d7-a645-61e068e388e9":{"id":"1834c9ea-8b48-56d7-a645-61e068e388e9","path":"/notes/sparse-models","title":"sparse-models","excerpt":"sparse-models Efficient representations of models that only contain \"useful\" information; sparisfication is the act of removing redundant…"},"8cd45cd5-f999-5885-9809-da5f2b004951":{"id":"8cd45cd5-f999-5885-9809-da5f2b004951","path":"/notes/stochastic-multiple-choice-learning","title":"stochastic-multiple-choice-learning","excerpt":"stochastic-multiple-choice-learning arxiv First written : Aug/20/2021, 14:26:50 Summary Comments"},"051d716b-497f-569c-b0a6-4b32e192d7ff":{"id":"051d716b-497f-569c-b0a6-4b32e192d7ff","path":"/notes/todo","title":"Todo","excerpt":"Todo You can create todos in Foam. This is an example of a todo list item that's complete This one is not completed yet You can mark it…"},"ca2e8227-4a51-527b-ba9c-66f4bca95406":{"id":"ca2e8227-4a51-527b-ba9c-66f4bca95406","path":"/notes/topological-sort","title":"topological-sort","excerpt":"topological-sort Sorting nodes of a graph to form an acyclic directed graph in the order they appear. For example, if   and  , then   should…"},"bd86e722-d930-5c0d-8e57-d72278691df5":{"id":"bd86e722-d930-5c0d-8e57-d72278691df5","path":"/notes/uncertainty","title":"uncertainty","excerpt":"uncertainty #aleatoric uncertainty is statistical uncertainty, i.e. in the frequentist view noisy measurements. #epistemic uncertainty is…"},"a1e16828-c852-5fc5-bb15-acb9e5e6df65":{"id":"a1e16828-c852-5fc5-bb15-acb9e5e6df65","path":"/notes/utility","title":"utility","excerpt":"utility The \"worth\" in a decision Need to unify with the algorithms book, but the wikipedia definition seems pretty intuitive; the utility…"},"0dff8916-86db-5c4c-bdee-c0c7be1cb322":{"id":"0dff8916-86db-5c4c-bdee-c0c7be1cb322","path":"/notes/variational autoencoder","title":"variational autoencoder","excerpt":"variational autoencoder A probabilistic [architecture] from the family of [autoencoders]. The self-learned representation is used to…"},"9c507678-b215-5271-af72-a5590078fdcc":{"id":"9c507678-b215-5271-af72-a5590078fdcc","path":"/notes/vicreg","title":"vicreg: Variance-invariance-covariance regularization for self-supervised learning","excerpt":"vicreg: Variance-invariance-covariance regularization for self-supervised learning arxiv First written : Sep/03/2021, 09:20:52 Summary Un…"},"054ca1e6-9d58-58b8-8cd1-8103b2e2f639":{"id":"054ca1e6-9d58-58b8-8cd1-8103b2e2f639","path":"/notes/virtual adversarial training","title":"virtual adversarial training","excerpt":"virtual adversarial training By  Miyato  et al. : A perturbation $\\Delta x = \\mathrm{arg max}_{\\Delta x} \\mathrm{KL}(p(y \\vert x) \\vert…"},"28e55559-f817-5ae8-8573-2549e989daef":{"id":"28e55559-f817-5ae8-8573-2549e989daef","path":"/notes/wandb-notes","title":"wandb-notes","excerpt":"wandb-notes Trying to conceptualize how to build in the  Weights and Biases  abstractions into standardized PyTorch workflows. Version track…"},"ef67e512-97cf-5c3c-ba8a-6d8b551a2538":{"id":"ef67e512-97cf-5c3c-ba8a-6d8b551a2538","path":"/.foam/templates/paper-review","title":"${1:$TM_FILENAME_BASE}","excerpt":"TM_FILENAME_BASE} arxiv First written :  {CURRENT_DATE}/ {CURRENT_MINUTE}:$CURRENT_SECOND Summary Comments"},"1783f312-8653-507d-89e8-2109b76242f0":{"id":"1783f312-8653-507d-89e8-2109b76242f0","path":"/notes/scaling-tensorflow-to-300mil","title":"scaling-tensorflow-to-300mil","excerpt":"scaling-tensorflow-to-300mil arxiv First written : Sep/22/2021, 12:23:32 Summary This is a case study paper on scaling up prediction systems…"}}